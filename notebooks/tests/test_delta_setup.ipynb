{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf265c5-c5e2-4549-93b4-6deca6478cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî HADOOP_HOME set to:, os.environ['HADOOP_HOME']\n",
      "‚úî Added to PATH: C:\\hadoop\\bin\n",
      "\n",
      " ‚úî winutils.exe: True\n",
      " ‚úî hadoop.dll: True\n",
      "\n",
      "üéâ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "from utils.spark_session import get_spark_session\n",
    "from utils.hadoop_setup import complete_hadoop_setup\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Hadoop setup run\n",
    "complete_hadoop_setup()\n",
    "\n",
    "# Create Spark Session and assign it to the 'spark' variable\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727f2ba1-0a6f-4b5e-88d7-1c9fd43c8dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Delta write successful!\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  2|delta|\n",
      "|  1| test|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(id=1, value=\"test\"),\n",
    "    Row(id=2, value=\"delta\")\n",
    "])\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"data/bronze/delta_test\")\n",
    "print(\"‚úì Delta write successful!\")\n",
    "\n",
    "df_read = spark.read.format(\"delta\").load(\"data/bronze/delta_test\")\n",
    "df_read.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7aba5e7-c8fc-4c73-8462-2646cc25f559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\chira\\Desktop\\data_engineering\\PySpark\\nyc-taxi-analytics-platform\\notebooks\n",
      "\n",
      "Looking for Delta files at: C:\\Users\\chira\\Desktop\\data_engineering\\PySpark\\nyc-taxi-analytics-platform\\notebooks\\data\\bronze\\delta_test\n",
      "Directory exists: True\n",
      "\n",
      "üìÅ Contents of C:\\Users\\chira\\Desktop\\data_engineering\\PySpark\\nyc-taxi-analytics-platform\\notebooks\\data\\bronze\\delta_test:\n",
      "  - .part-00000-141e0885-afcf-423d-b2e8-6f3a1c6cf1c6-c000.snappy.parquet.crc (12 bytes)\n",
      "  - .part-00000-8cec9c85-0154-46a8-827f-7956184ce989-c000.snappy.parquet.crc (12 bytes)\n",
      "  - .part-00001-6a74c096-d96c-44eb-bee9-4d1e9a8510dc-c000.snappy.parquet.crc (16 bytes)\n",
      "  - .part-00001-909d77f1-9f2d-4dec-843d-37dda9d57f69-c000.snappy.parquet.crc (16 bytes)\n",
      "  - .part-00003-cddda00e-4120-4a25-8626-c84c2e1263a4-c000.snappy.parquet.crc (16 bytes)\n",
      "  - .part-00003-e2097b30-e663-4eeb-9dc5-d6f3480b62c6-c000.snappy.parquet.crc (16 bytes)\n",
      "  - part-00000-141e0885-afcf-423d-b2e8-6f3a1c6cf1c6-c000.snappy.parquet (381 bytes)\n",
      "  - part-00000-8cec9c85-0154-46a8-827f-7956184ce989-c000.snappy.parquet (381 bytes)\n",
      "  - part-00001-6a74c096-d96c-44eb-bee9-4d1e9a8510dc-c000.snappy.parquet (715 bytes)\n",
      "  - part-00001-909d77f1-9f2d-4dec-843d-37dda9d57f69-c000.snappy.parquet (715 bytes)\n",
      "  - part-00003-cddda00e-4120-4a25-8626-c84c2e1263a4-c000.snappy.parquet (722 bytes)\n",
      "  - part-00003-e2097b30-e663-4eeb-9dc5-d6f3480b62c6-c000.snappy.parquet (722 bytes)\n",
      "  - _delta_log\\.00000000000000000000.json.crc (20 bytes)\n",
      "  - _delta_log\\.00000000000000000001.json.crc (20 bytes)\n",
      "  - _delta_log\\00000000000000000000.json (1,434 bytes)\n",
      "  - _delta_log\\00000000000000000001.json (1,427 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"Current working directory: {cwd}\")\n",
    "\n",
    "# Check where delta files were written\n",
    "delta_path = cwd / \"data\" / \"bronze\" / \"delta_test\"\n",
    "print(f\"\\nLooking for Delta files at: {delta_path}\")\n",
    "print(f\"Directory exists: {delta_path.exists()}\")\n",
    "\n",
    "if delta_path.exists():\n",
    "    print(f\"\\nüìÅ Contents of {delta_path}:\")\n",
    "    for item in delta_path.rglob(\"*\"):\n",
    "        if item.is_file():\n",
    "            size = item.stat().st_size\n",
    "            print(f\"  - {item.relative_to(delta_path)} ({size:,} bytes)\")\n",
    "else:\n",
    "    # Check if it was written somewhere else\n",
    "    print(\"\\nüîç Searching for delta_test directory...\")\n",
    "    home = Path.home()\n",
    "    for path in home.rglob(\"delta_test\"):\n",
    "        if path.is_dir():\n",
    "            print(f\"  Found at: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40600aa-cf6e-4e35-968b-3e6ba44c3aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Conda)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
